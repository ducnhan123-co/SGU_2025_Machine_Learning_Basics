{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78888fac-dfab-4128-9a51-88cd52222a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== 5-FOLD CV (log target) ====\n",
      "RandomForest: RMSE=0.15176 ± 0.01394\n",
      "XGB: RMSE=0.14060 ± 0.01101\n",
      "✅ Saved to submission_final.csv\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 1. IMPORTS\n",
    "# =========================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# =========================================\n",
    "# 2. LOAD DATA\n",
    "# =========================================\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# =========================================\n",
    "# 3. HÀM DROP CỘT NHIỀU NULL + NHIỀU ZERO\n",
    "#    (áp dụng cho cả train và test để đồng bộ)\n",
    "# =========================================\n",
    "def drop_null_and_zero(train_df, test_df, null_threshold=500, zero_ratio=0.5):\n",
    "    # 3.1 drop cột quá nhiều null trong train\n",
    "    cols_null = []\n",
    "    for col in train_df.columns:\n",
    "        if train_df[col].isnull().sum() > null_threshold:\n",
    "            cols_null.append(col)\n",
    "    train_df = train_df.drop(columns=cols_null)\n",
    "    # test cũng drop cùng cột\n",
    "    test_df = test_df.drop(columns=[c for c in cols_null if c in test_df.columns], errors=\"ignore\")\n",
    "\n",
    "    # 3.2 drop cột có > zero_ratio là 0\n",
    "    def _drop_zero_cols(df, cols_to_check):\n",
    "        n_rows = len(df)\n",
    "        cols_drop = []\n",
    "        for c in cols_to_check:\n",
    "            zero_count = (df[c] == 0).sum()\n",
    "            if zero_count / n_rows > zero_ratio:\n",
    "                cols_drop.append(c)\n",
    "        return cols_drop\n",
    "\n",
    "    # chỉ check trên train, sau đó drop cả 2\n",
    "    numeric_cols = train_df.select_dtypes(include=[np.number]).columns\n",
    "    zero_cols = _drop_zero_cols(train_df, numeric_cols)\n",
    "\n",
    "    train_df = train_df.drop(columns=zero_cols)\n",
    "    test_df = test_df.drop(columns=[c for c in zero_cols if c in test_df.columns], errors=\"ignore\")\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "train_clean, test_clean = drop_null_and_zero(train, test, null_threshold=500, zero_ratio=0.5)\n",
    "\n",
    "# =========================================\n",
    "# 4. FEATURE ENGINEERING (THEO LOGIC BẠN ĐÃ LÀM)\n",
    "# =========================================\n",
    "def prepare_features(train_df, test_df, target_col=\"SalePrice\"):\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "\n",
    "    # ---- chọn các cột gốc cần dùng (khoảng 30 cột + vài cột FE)\n",
    "    base_cols = [\n",
    "        'MSZoning','LotArea','LotConfig','LandSlope','Neighborhood',\n",
    "        'HouseStyle','OverallQual','YearBuilt','YearRemodAdd',\n",
    "        'RoofStyle','Exterior1st','Exterior2nd','ExterQual','Foundation',\n",
    "        'BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','TotalBsmtSF',\n",
    "        'HeatingQC','CentralAir','1stFlrSF','GrLivArea','FullBath',\n",
    "        'TotRmsAbvGrd','GarageType','GarageFinish','GarageCars','GarageArea',\n",
    "        'PavedDrive','MoSold','YrSold','SaleType','SaleCondition'\n",
    "    ]\n",
    "\n",
    "    # đôi khi 1 số cột sau khi drop ở trên sẽ mất → chỉ giữ cột còn tồn tại\n",
    "    base_cols = [c for c in base_cols if c in train_df.columns]\n",
    "\n",
    "    # lấy train_X\n",
    "    train_X = train_df[base_cols].copy()\n",
    "    # lấy test_X\n",
    "    test_X = test_df[[c for c in base_cols if c in test_df.columns]].copy()\n",
    "\n",
    "    # =============================\n",
    "    # 4.1 MAP / RÚT GỌN CÁC CỘT CATEGORICAL\n",
    "    # =============================\n",
    "\n",
    "    # BsmtFinType1\n",
    "    col_BsmtFinType1 = {'Unf': 1, 'GLQ': 2, 'ALQ': 3, 'BLQ': 3, 'Rec': 3, 'LwQ': 3}\n",
    "    for df in [train_X, test_X]:\n",
    "        if 'BsmtFinType1' in df.columns:\n",
    "            df['BsmtFinType1'] = df['BsmtFinType1'].map(col_BsmtFinType1).fillna(4)\n",
    "\n",
    "    # BsmtExposure\n",
    "    col_BsmtExposure = {'No': 1, 'Av': 2, 'Mn': 2, 'Gd': 3}\n",
    "    for df in [train_X, test_X]:\n",
    "        if 'BsmtExposure' in df.columns:\n",
    "            df['BsmtExposure'] = df['BsmtExposure'].map(col_BsmtExposure).fillna(4)\n",
    "\n",
    "    # BsmtQual\n",
    "    col_BsmtQual = {'TA':1, 'Fa':1, 'Gd':2, 'Ex':3}\n",
    "    for df in [train_X, test_X]:\n",
    "        if 'BsmtQual' in df.columns:\n",
    "            df['BsmtQual'] = df['BsmtQual'].map(col_BsmtQual)\n",
    "\n",
    "    # Exterior1st\n",
    "    for df in [train_X, test_X]:\n",
    "        if 'Exterior1st' in df.columns:\n",
    "            df['Exterior1st'] = df['Exterior1st'].apply(\n",
    "                lambda x: x if x in ['VinylSd','MetalSd','Wd Sdng','HdBoard','Plywood','Stucco'] else 'others'\n",
    "            )\n",
    "            map_ex1 = {'VinylSd':1, 'MetalSd':2, 'Wd Sdng':2, 'HdBoard':2, 'Plywood':2, 'Stucco':2, 'others':3}\n",
    "            df['Exterior1st'] = df['Exterior1st'].map(map_ex1)\n",
    "\n",
    "    # Exterior2nd\n",
    "    for df in [train_X, test_X]:\n",
    "        if 'Exterior2nd' in df.columns:\n",
    "            df['Exterior2nd'] = df['Exterior2nd'].apply(\n",
    "                lambda x: x if x in ['VinylSd','MetalSd','HdBoard','Wd Sdng','Plywood'] else 'others'\n",
    "            )\n",
    "            map_ex2 = {'VinylSd':1, 'MetalSd':2, 'HdBoard':3, 'Wd Sdng':4, 'Plywood':5, 'others':6}\n",
    "            df['Exterior2nd'] = df['Exterior2nd'].map(map_ex2)\n",
    "\n",
    "    # ExterQual\n",
    "    for df in [train_X, test_X]:\n",
    "        if 'ExterQual' in df.columns:\n",
    "            df['ExterQual'] = df['ExterQual'].apply(lambda x: x if x in ['TA','Gd'] else 'others')\n",
    "            map_exq = {'TA':1, 'Gd':2, 'others':3}\n",
    "            df['ExterQual'] = df['ExterQual'].map(map_exq)\n",
    "\n",
    "    # Foundation\n",
    "    for df in [train_X, test_X]:\n",
    "        if 'Foundation' in df.columns:\n",
    "            df['Foundation'] = df['Foundation'].apply(lambda x: x if x in ['PConc','CBlock','BrkTil'] else 'others')\n",
    "            map_f = {'PConc':1, 'CBlock':2, 'BrkTil':3, 'others':4}\n",
    "            df['Foundation'] = df['Foundation'].map(map_f)\n",
    "\n",
    "    # GarageFinish\n",
    "    for df in [train_X, test_X]:\n",
    "        if 'GarageFinish' in df.columns:\n",
    "            df['GarageFinish'] = df['GarageFinish'].fillna('others')\n",
    "            map_gf = {'Unf':1, 'RFn':2, 'Fin':3, 'others':4}\n",
    "            df['GarageFinish'] = df['GarageFinish'].map(map_gf)\n",
    "\n",
    "    # GarageType\n",
    "    for df in [train_X, test_X]:\n",
    "        if 'GarageType' in df.columns:\n",
    "            df['GarageType'] = df['GarageType'].apply(lambda x: x if x in ['Attchd','Detchd'] else 'others')\n",
    "            map_gt = {'Attchd':1, 'Detchd':2, 'others':3}\n",
    "            df['GarageType'] = df['GarageType'].map(map_gt)\n",
    "\n",
    "    # HeatingQC\n",
    "    for df in [train_X, test_X]:\n",
    "        if 'HeatingQC' in df.columns:\n",
    "            df['HeatingQC'] = df['HeatingQC'].apply(lambda x: x if x in ['Ex','TA','Gd'] else 'others')\n",
    "            map_hq = {'Ex':1, 'TA':2, 'Gd':3, 'others':4}\n",
    "            df['HeatingQC'] = df['HeatingQC'].map(map_hq)\n",
    "\n",
    "    # HouseStyle\n",
    "    for df in [train_X, test_X]:\n",
    "        if 'HouseStyle' in df.columns:\n",
    "            df['HouseStyle'] = df['HouseStyle'].apply(lambda x: x if x in ['1Story','2Story','1.5Fin'] else 'others')\n",
    "            map_hs = {'1Story':1, '2Story':2, '1.5Fin':3, 'others':4}\n",
    "            df['HouseStyle'] = df['HouseStyle'].map(map_hs)\n",
    "\n",
    "    # KitchenQual nếu có\n",
    "    for df in [train_X, test_X]:\n",
    "        if 'KitchenQual' in df.columns:\n",
    "            df['KitchenQual'] = df['KitchenQual'].apply(lambda x: x if x in ['TA','Gd','Ex'] else 'others')\n",
    "            map_kq = {'TA':1, 'Gd':2, 'Ex':3, 'others':4}\n",
    "            df['KitchenQual'] = df['KitchenQual'].map(map_kq)\n",
    "\n",
    "    # LandSlope: bạn drop vì lệch → drop luôn\n",
    "    for df in [train_X, test_X]:\n",
    "        if 'LandSlope' in df.columns:\n",
    "            df.drop(columns=['LandSlope'], inplace=True)\n",
    "\n",
    "    # LotConfig\n",
    "    for df in [train_X, test_X]:\n",
    "        if 'LotConfig' in df.columns:\n",
    "            df['LotConfig'] = df['LotConfig'].apply(lambda x: x if x in ['Inside','Corner'] else 'others')\n",
    "            map_lc = {'Inside':1, 'Corner':2, 'others':3}\n",
    "            df['LotConfig'] = df['LotConfig'].map(map_lc)\n",
    "\n",
    "    # LotShape\n",
    "    for df in [train_X, test_X]:\n",
    "        if 'LotShape' in df.columns:\n",
    "            df['LotShape'] = df['LotShape'].apply(lambda x: x if x in ['Reg','IR1'] else 'others')\n",
    "            map_ls = {'Reg':1, 'IR1':2, 'others':3}\n",
    "            df['LotShape'] = df['LotShape'].map(map_ls)\n",
    "\n",
    "    # MSZoning\n",
    "    for df in [train_X, test_X]:\n",
    "        if 'MSZoning' in df.columns:\n",
    "            df['MSZoning'] = df['MSZoning'].apply(lambda x: x if x in ['RL','RM'] else 'others')\n",
    "            map_ms = {'RL':1, 'RM':2, 'others':3}\n",
    "            df['MSZoning'] = df['MSZoning'].map(map_ms)\n",
    "\n",
    "    # RoofStyle\n",
    "    for df in [train_X, test_X]:\n",
    "        if 'RoofStyle' in df.columns:\n",
    "            df['RoofStyle'] = df['RoofStyle'].apply(lambda x: x if x in ['Gable','Hip'] else 'others')\n",
    "            map_rs = {'Gable':1, 'Hip':2, 'others':3}\n",
    "            df['RoofStyle'] = df['RoofStyle'].map(map_rs)\n",
    "\n",
    "    # SaleCondition\n",
    "    for df in [train_X, test_X]:\n",
    "        if 'SaleCondition' in df.columns:\n",
    "            df['SaleCondition'] = df['SaleCondition'].apply(\n",
    "                lambda x: x if x in ['Normal','Partial','Abnorml'] else 'others'\n",
    "            )\n",
    "            map_sc = {'Normal':1, 'Partial':2, 'Abnorml':3, 'others':4}\n",
    "            df['SaleCondition'] = df['SaleCondition'].map(map_sc)\n",
    "\n",
    "    # ============== Neighborhood: target-mean encoding thủ công ==============\n",
    "    if 'Neighborhood' in train_X.columns:\n",
    "        nb_mean = train_df.groupby('Neighborhood')[target_col].mean()\n",
    "        # map train\n",
    "        train_X['Neighborhood'] = train_X['Neighborhood'].map(nb_mean)\n",
    "        # test: nếu ko có trong train → fill bằng mean chung\n",
    "        global_mean = train_df[target_col].mean()\n",
    "        test_X['Neighborhood'] = test_X['Neighborhood'].map(nb_mean).fillna(global_mean)\n",
    "\n",
    "        # scale\n",
    "        scaler_nb = StandardScaler()\n",
    "        train_X[['Neighborhood']] = scaler_nb.fit_transform(train_X[['Neighborhood']])\n",
    "        test_X[['Neighborhood']] = scaler_nb.transform(test_X[['Neighborhood']])\n",
    "\n",
    "    # ============== Feature engineering numeric ===============\n",
    "    # HouseAge = YrSold - YearBuilt\n",
    "    if ('YrSold' in train_X.columns) and ('YearBuilt' in train_X.columns):\n",
    "        train_X['HouseAge'] = train_X['YrSold'] - train_X['YearBuilt']\n",
    "        test_X['HouseAge'] = test_X['YrSold'] - test_X['YearBuilt']\n",
    "        scaler_age = StandardScaler()\n",
    "        train_X[['HouseAge']] = scaler_age.fit_transform(train_X[['HouseAge']])\n",
    "        test_X[['HouseAge']] = scaler_age.transform(test_X[['HouseAge']])\n",
    "\n",
    "    # IsRemodeled\n",
    "    if ('YearRemodAdd' in train_X.columns) and ('YearBuilt' in train_X.columns):\n",
    "        train_X['IsRemodeled'] = (train_X['YearRemodAdd'] != train_X['YearBuilt']).astype(int)\n",
    "        test_X['IsRemodeled'] = (test_X['YearRemodAdd'] != test_X['YearBuilt']).astype(int)\n",
    "\n",
    "    # Scale mấy cột liên tục quan trọng\n",
    "    for col in ['TotalBsmtSF','1stFlrSF','GrLivArea','LotArea','GarageArea']:\n",
    "        if col in train_X.columns:\n",
    "            scaler_tmp = StandardScaler()\n",
    "            train_X[[col]] = scaler_tmp.fit_transform(train_X[[col]])\n",
    "            if col in test_X.columns:\n",
    "                test_X[[col]] = scaler_tmp.transform(test_X[[col]])\n",
    "\n",
    "    # Has3FullBath\n",
    "    if 'FullBath' in train_X.columns:\n",
    "        train_X['Has3FullBath'] = (train_X['FullBath'] >= 3).astype(int)\n",
    "        test_X['Has3FullBath'] = (test_X['FullBath'] >= 3).astype(int)\n",
    "\n",
    "    # Has3Garage\n",
    "    if 'GarageCars' in train_X.columns:\n",
    "        train_X['Has3Garage'] = (train_X['GarageCars'] == 3).astype(int)\n",
    "        test_X['Has3Garage'] = (test_X['GarageCars'] == 3).astype(int)\n",
    "\n",
    "    # GarageArea_per_car\n",
    "    if ('GarageArea' in train_X.columns) and ('GarageCars' in train_X.columns):\n",
    "        train_X['GarageArea_per_car'] = train_X['GarageArea'] / (train_X['GarageCars'] + 1)\n",
    "        test_X['GarageArea_per_car'] = test_X['GarageArea'] / (test_X['GarageCars'] + 1)\n",
    "        scaler_g = StandardScaler()\n",
    "        train_X[['GarageArea','GarageArea_per_car']] = scaler_g.fit_transform(\n",
    "            train_X[['GarageArea','GarageArea_per_car']]\n",
    "        )\n",
    "        test_X[['GarageArea','GarageArea_per_car']] = scaler_g.transform(\n",
    "            test_X[['GarageArea','GarageArea_per_car']]\n",
    "        )\n",
    "\n",
    "    # cuối cùng: drop mấy cột gốc ko cần nữa\n",
    "    drop_cols = ['YearBuilt','YrSold','YearRemodAdd','TotRmsAbvGrd']\n",
    "    for df in [train_X, test_X]:\n",
    "        for c in drop_cols:\n",
    "            if c in df.columns:\n",
    "                df.drop(columns=[c], inplace=True)\n",
    "\n",
    "    # =============================\n",
    "    # 4.2 Encode mọi object còn sót (phòng hờ)\n",
    "    # =============================\n",
    "    for df in [train_X, test_X]:\n",
    "        obj_cols = df.select_dtypes(include='object').columns\n",
    "        for col in obj_cols:\n",
    "            le = LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "    # gắn lại target\n",
    "    train_X[target_col] = train_df[target_col].values\n",
    "\n",
    "    return train_X, test_X\n",
    "\n",
    "# =========================================\n",
    "# 5. GỌI HÀM FEATURE ENGINEERING\n",
    "# =========================================\n",
    "train_X, test_X = prepare_features(train_clean, test_clean, target_col=\"SalePrice\")\n",
    "\n",
    "# =========================================\n",
    "# 6. TÁCH X, y + ĐỒNG BỘ CỘT\n",
    "# =========================================\n",
    "X = train_X.drop(columns=['SalePrice'])\n",
    "y_log = np.log1p(train_X['SalePrice'])\n",
    "\n",
    "# Đồng bộ cột giữa train và test (rất quan trọng!)\n",
    "test_X = test_X.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "# =========================================\n",
    "# 7. CROSS-VALIDATION ĐỂ XEM RMSE\n",
    "# =========================================\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestRegressor(\n",
    "        n_estimators=500,\n",
    "        max_depth=15,\n",
    "        min_samples_split=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \"XGB\": XGBRegressor(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        tree_method=\"hist\"\n",
    "    )\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rmse_scorer = make_scorer(lambda yt, yp: np.sqrt(mean_squared_error(yt, yp)), greater_is_better=False)\n",
    "\n",
    "print(\"==== 5-FOLD CV (log target) ====\")\n",
    "for name, model in models.items():\n",
    "    scores = -cross_val_score(model, X, y_log, scoring=rmse_scorer, cv=kf)\n",
    "    print(f\"{name}: RMSE={scores.mean():.5f} ± {scores.std():.5f}\")\n",
    "\n",
    "# =========================================\n",
    "# 8. TRAIN FINAL MODEL + PREDICT + SUBMISSION\n",
    "# =========================================\n",
    "best_model = XGBRegressor(\n",
    "    n_estimators=1200,\n",
    "    learning_rate=0.04,\n",
    "    max_depth=6,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.85,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\"\n",
    ")\n",
    "\n",
    "best_model.fit(X, y_log)\n",
    "pred_log = best_model.predict(test_X)\n",
    "pred = np.expm1(pred_log)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"Id\": test[\"Id\"],\n",
    "    \"SalePrice\": pred\n",
    "})\n",
    "\n",
    "# Lưu file\n",
    "submission.to_csv(\"submission_final.csv\", index=False)\n",
    "print(\"✅ Saved to submission_final.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32e25e5e-eb90-4df0-a980-cc0cd30a1862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB (rich): 0.12087 ± 0.00985\n",
      "RF  (rich): 0.14037 ± 0.00930\n",
      "✅ saved submission_blend.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# =============== 1. LOAD ===============\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# =============== 2. DROP OUTLIER ===============\n",
    "# classic Kaggle outliers\n",
    "train = train.drop(train[(train['GrLivArea'] > 4000) & (train['SalePrice'] < 300000)].index)\n",
    "\n",
    "# =============== 3. GỘP ĐỂ XỬ LÝ CHUNG ===============\n",
    "train_y = np.log1p(train[\"SalePrice\"])\n",
    "train_id = train[\"Id\"]\n",
    "test_id = test[\"Id\"]\n",
    "\n",
    "train.drop(columns=[\"SalePrice\"], inplace=True)\n",
    "\n",
    "full = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "\n",
    "# =============== 4. FILL MISSING ===============\n",
    "# numeric -> 0\n",
    "num_cols = full.select_dtypes(include=[np.number]).columns\n",
    "full[num_cols] = full[num_cols].fillna(0)\n",
    "\n",
    "# object -> \"None\"\n",
    "obj_cols = full.select_dtypes(include=[\"object\"]).columns\n",
    "full[obj_cols] = full[obj_cols].fillna(\"None\")\n",
    "\n",
    "# =============== 5. LOG TRANSFORM CÁC CỘT LỆCH ===============\n",
    "skew_cols = [\"LotArea\", \"GrLivArea\", \"1stFlrSF\", \"2ndFlrSF\", \"TotalBsmtSF\", \"LowQualFinSF\"]\n",
    "for c in skew_cols:\n",
    "    if c in full.columns:\n",
    "        full[c] = np.log1p(full[c])\n",
    "\n",
    "# =============== 6. ONE-HOT ===============\n",
    "full = pd.get_dummies(full, drop_first=True)\n",
    "\n",
    "# tách lại\n",
    "n_train = len(train_y)\n",
    "train_X = full.iloc[:n_train, :].copy()\n",
    "test_X = full.iloc[n_train:, :].copy()\n",
    "\n",
    "# =============== 7. CV SCORER ===============\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rmse_scorer = make_scorer(lambda yt, yp: np.sqrt(mean_squared_error(yt, yp)), greater_is_better=False)\n",
    "\n",
    "# =============== 8. MODELS ===============\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=1400,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=4,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.001,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\"\n",
    ")\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=700,\n",
    "    max_depth=18,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# =============== 9. CV ===============\n",
    "xgb_scores = -cross_val_score(xgb_model, train_X, train_y, scoring=rmse_scorer, cv=kf)\n",
    "rf_scores  = -cross_val_score(rf_model, train_X, train_y, scoring=rmse_scorer, cv=kf)\n",
    "\n",
    "print(f\"XGB (rich): {xgb_scores.mean():.5f} ± {xgb_scores.std():.5f}\")\n",
    "print(f\"RF  (rich): {rf_scores.mean():.5f} ± {rf_scores.std():.5f}\")\n",
    "\n",
    "# =============== 10. FIT FULL + BLEND ===============\n",
    "xgb_model.fit(train_X, train_y)\n",
    "rf_model.fit(train_X, train_y)\n",
    "\n",
    "pred_xgb = np.expm1(xgb_model.predict(test_X))\n",
    "pred_rf  = np.expm1(rf_model.predict(test_X))\n",
    "\n",
    "# blend 0.7 xgb + 0.3 rf\n",
    "pred_final = 0.7 * pred_xgb + 0.3 * pred_rf\n",
    "\n",
    "sub = pd.DataFrame({\n",
    "    \"Id\": test_id,\n",
    "    \"SalePrice\": pred_final\n",
    "})\n",
    "sub.to_csv(\"submission_blend.csv\", index=False)\n",
    "print(\"✅ saved submission_blend.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00ab214b-a8f8-4845-979c-f4c183899776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB deep   : 0.12260 ± 0.00946\n",
      "XGB shallow: 0.11854 ± 0.00824\n",
      "✅ saved submission_tuned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# =============== 1. LOAD ===============\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# drop outlier kinh điển\n",
    "train = train.drop(train[(train['GrLivArea'] > 4000) & (train['SalePrice'] < 300000)].index)\n",
    "\n",
    "y = np.log1p(train[\"SalePrice\"])\n",
    "train_id = train[\"Id\"]\n",
    "test_id = test[\"Id\"]\n",
    "\n",
    "train = train.drop(columns=[\"SalePrice\"])\n",
    "\n",
    "# =============== 2. CONCAT ===============\n",
    "full = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "\n",
    "# =============== 3. FILL MISSING ===============\n",
    "num_cols = full.select_dtypes(include=[np.number]).columns\n",
    "obj_cols = full.select_dtypes(include=['object']).columns\n",
    "\n",
    "full[num_cols] = full[num_cols].fillna(0)\n",
    "full[obj_cols] = full[obj_cols].fillna(\"None\")\n",
    "\n",
    "# =============== 4. FEATURE ENGINEERING NHẸ ===============\n",
    "# log mấy cột lệch\n",
    "skew_cols = [\"LotArea\", \"GrLivArea\", \"1stFlrSF\", \"2ndFlrSF\", \"TotalBsmtSF\", \"LowQualFinSF\"]\n",
    "for c in skew_cols:\n",
    "    if c in full.columns:\n",
    "        full[c] = np.log1p(full[c])\n",
    "\n",
    "# tổng diện tích sàn kiểu Kaggle\n",
    "full[\"TotalSF\"] = full[\"TotalBsmtSF\"] + full[\"1stFlrSF\"] + full[\"2ndFlrSF\"]\n",
    "\n",
    "# overall quality x diện tích\n",
    "full[\"Qual_x_GrLiv\"] = full[\"OverallQual\"] * (full[\"GrLivArea\"])\n",
    "\n",
    "# tuổi nhà + năm sửa\n",
    "full[\"HouseAge\"] = full[\"YrSold\"] - full[\"YearBuilt\"]\n",
    "full[\"RemodAge\"] = full[\"YrSold\"] - full[\"YearRemodAdd\"]\n",
    "full[\"HouseAge\"] = full[\"HouseAge\"].clip(lower=0)\n",
    "full[\"RemodAge\"] = full[\"RemodAge\"].clip(lower=0)\n",
    "\n",
    "# có hầm không\n",
    "full[\"HasBsmt\"] = (full[\"TotalBsmtSF\"] > 0).astype(int)\n",
    "\n",
    "# mấy cột rất lệch / gần như 1 giá trị -> bỏ\n",
    "low_var_cols = [\"Street\", \"Utilities\", \"Condition2\", \"RoofMatl\", \"PoolArea\", \"PoolQC\",\n",
    "                \"MiscVal\", \"MiscFeature\"]\n",
    "for c in low_var_cols:\n",
    "    if c in full.columns:\n",
    "        full = full.drop(columns=[c])\n",
    "\n",
    "# =============== 5. ONE-HOT ===============\n",
    "full = pd.get_dummies(full, drop_first=True)\n",
    "\n",
    "# =============== 6. TÁCH LẠI ===============\n",
    "n_train = len(y)\n",
    "X = full.iloc[:n_train, :].copy()\n",
    "X_test = full.iloc[n_train:, :].copy()\n",
    "\n",
    "# =============== 7. SCORER + CV ===============\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rmse_scorer = make_scorer(lambda yt, yp: np.sqrt(mean_squared_error(yt, yp)), greater_is_better=False)\n",
    "\n",
    "# =============== 8. 2 XGB KHÁC NHAU ===============\n",
    "xgb_deep = XGBRegressor(\n",
    "    n_estimators=1600,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.7,\n",
    "    min_child_weight=3,\n",
    "    reg_lambda=1.0,\n",
    "    reg_alpha=0.0,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\"\n",
    ")\n",
    "\n",
    "xgb_shallow = XGBRegressor(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.02,\n",
    "    max_depth=3,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.6,\n",
    "    min_child_weight=2,\n",
    "    reg_lambda=1.2,\n",
    "    reg_alpha=0.001,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\"\n",
    ")\n",
    "\n",
    "# CV nhanh để xem\n",
    "scores_deep = -cross_val_score(xgb_deep, X, y, scoring=rmse_scorer, cv=kf)\n",
    "scores_shallow = -cross_val_score(xgb_shallow, X, y, scoring=rmse_scorer, cv=kf)\n",
    "print(f\"XGB deep   : {scores_deep.mean():.5f} ± {scores_deep.std():.5f}\")\n",
    "print(f\"XGB shallow: {scores_shallow.mean():.5f} ± {scores_shallow.std():.5f}\")\n",
    "\n",
    "# =============== 9. FIT FULL + BLEND ===============\n",
    "xgb_deep.fit(X, y)\n",
    "xgb_shallow.fit(X, y)\n",
    "\n",
    "pred1 = np.expm1(xgb_deep.predict(X_test))\n",
    "pred2 = np.expm1(xgb_shallow.predict(X_test))\n",
    "\n",
    "# blend: shallow thường generalize tốt hơn -> cho weight cao hơn\n",
    "final_pred = 0.4 * pred1 + 0.6 * pred2\n",
    "\n",
    "sub = pd.DataFrame({\n",
    "    \"Id\": test_id,\n",
    "    \"SalePrice\": final_pred\n",
    "})\n",
    "sub.to_csv(\"submission_tuned.csv\", index=False)\n",
    "print(\"✅ saved submission_tuned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ae1846e-8396-41c1-9a97-02fc5dfbdaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB_shallow: 0.11854 ± 0.00824\n",
      "XGB_wide: 0.12703 ± 0.00971\n",
      "XGB_deeplite: 0.12791 ± 0.00981\n",
      "✅ saved submission_blend3.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# ====== 1. LOAD + PREP y ======\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test  = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# bỏ outlier kinh điển\n",
    "train = train.drop(train[(train['GrLivArea'] > 4000) & (train['SalePrice'] < 300000)].index)\n",
    "\n",
    "y = np.log1p(train[\"SalePrice\"])\n",
    "test_id = test[\"Id\"]\n",
    "\n",
    "train = train.drop(columns=[\"SalePrice\"])\n",
    "full = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "\n",
    "# ====== 2. FILL ======\n",
    "num_cols = full.select_dtypes(include=[np.number]).columns\n",
    "obj_cols = full.select_dtypes(include=[\"object\"]).columns\n",
    "full[num_cols] = full[num_cols].fillna(0)\n",
    "full[obj_cols] = full[obj_cols].fillna(\"None\")\n",
    "\n",
    "# ====== 3. FE ======\n",
    "skew_cols = [\"LotArea\",\"GrLivArea\",\"1stFlrSF\",\"2ndFlrSF\",\"TotalBsmtSF\",\"LowQualFinSF\"]\n",
    "for c in skew_cols:\n",
    "    if c in full.columns:\n",
    "        full[c] = np.log1p(full[c])\n",
    "\n",
    "full[\"TotalSF\"] = full[\"TotalBsmtSF\"] + full[\"1stFlrSF\"] + full[\"2ndFlrSF\"]\n",
    "full[\"Qual_x_GrLiv\"] = full[\"OverallQual\"] * full[\"GrLivArea\"]\n",
    "full[\"HouseAge\"] = (full[\"YrSold\"] - full[\"YearBuilt\"]).clip(lower=0)\n",
    "full[\"RemodAge\"] = (full[\"YrSold\"] - full[\"YearRemodAdd\"]).clip(lower=0)\n",
    "full[\"HasBsmt\"] = (full[\"TotalBsmtSF\"] > 0).astype(int)\n",
    "\n",
    "low_var_cols = [\"Street\",\"Utilities\",\"Condition2\",\"RoofMatl\",\"PoolArea\",\"PoolQC\",\"MiscVal\",\"MiscFeature\"]\n",
    "for c in low_var_cols:\n",
    "    if c in full.columns:\n",
    "        full = full.drop(columns=[c])\n",
    "\n",
    "# ====== 4. ONE-HOT ======\n",
    "full = pd.get_dummies(full, drop_first=True)\n",
    "\n",
    "# ====== 5. SPLIT LẠI ======\n",
    "n_train = len(y)\n",
    "X = full.iloc[:n_train, :].copy()\n",
    "X_test = full.iloc[n_train:, :].copy()\n",
    "\n",
    "# ====== 6. CV SETUP ======\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rmse_scorer = make_scorer(lambda yt, yp: np.sqrt(mean_squared_error(yt, yp)), greater_is_better=False)\n",
    "\n",
    "# ====== 7. MODEL 1: SHALLOW (đang tốt) ======\n",
    "xgb_shallow = XGBRegressor(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.02,\n",
    "    max_depth=3,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.6,\n",
    "    min_child_weight=2,\n",
    "    reg_lambda=1.2,\n",
    "    reg_alpha=0.001,\n",
    "    gamma=0.0,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\"\n",
    ")\n",
    "\n",
    "# ====== 8. MODEL 2: WIDE (depth=2, nhiều cây) ======\n",
    "xgb_wide = XGBRegressor(\n",
    "    n_estimators=2500,\n",
    "    learning_rate=0.018,\n",
    "    max_depth=2,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.55,\n",
    "    min_child_weight=3,\n",
    "    reg_lambda=1.3,\n",
    "    reg_alpha=0.01,\n",
    "    gamma=0.1,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\"\n",
    ")\n",
    "\n",
    "# ====== 9. MODEL 3: DEEP-LITE (depth=4, regularize) ======\n",
    "xgb_deeplite = XGBRegressor(\n",
    "    n_estimators=1400,\n",
    "    learning_rate=0.028,\n",
    "    max_depth=4,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.6,\n",
    "    min_child_weight=4,\n",
    "    reg_lambda=1.4,\n",
    "    reg_alpha=0.02,\n",
    "    gamma=0.15,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\"\n",
    ")\n",
    "\n",
    "# ====== 10. CV NHANH ======\n",
    "for name, mdl in {\n",
    "    \"XGB_shallow\": xgb_shallow,\n",
    "    \"XGB_wide\": xgb_wide,\n",
    "    \"XGB_deeplite\": xgb_deeplite\n",
    "}.items():\n",
    "    scores = -cross_val_score(mdl, X, y, scoring=rmse_scorer, cv=kf)\n",
    "    print(f\"{name}: {scores.mean():.5f} ± {scores.std():.5f}\")\n",
    "\n",
    "# ====== 11. TRAIN FULL + BLEND ======\n",
    "xgb_shallow.fit(X, y)\n",
    "xgb_wide.fit(X, y)\n",
    "xgb_deeplite.fit(X, y)\n",
    "\n",
    "p1 = np.expm1(xgb_shallow.predict(X_test))\n",
    "p2 = np.expm1(xgb_wide.predict(X_test))\n",
    "p3 = np.expm1(xgb_deeplite.predict(X_test))\n",
    "\n",
    "# weight ưu tiên model tốt nhất (shallow)\n",
    "final_pred = 0.60 * p1 + 0.25 * p2 + 0.15 * p3\n",
    "\n",
    "sub = pd.DataFrame({\n",
    "    \"Id\": test_id,\n",
    "    \"SalePrice\": final_pred\n",
    "})\n",
    "sub.to_csv(\"submission_blend3.csv\", index=False)\n",
    "print(\"✅ saved submission_blend3.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86b004a6-91e3-46af-9ca2-e766865d0700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BASE ===\n",
      "BASE XGB: 0.11854 ± 0.00824\n",
      "=== TUNED ===\n",
      "TUNED XGB: 0.11738 ± 0.00930\n",
      "✅ saved submission_best_xgb.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# --- chuẩn bị như trước ---\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test  = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# bỏ outlier kinh điển\n",
    "train = train.drop(train[(train['GrLivArea'] > 4000) & (train['SalePrice'] < 300000)].index)\n",
    "\n",
    "y = np.log1p(train[\"SalePrice\"])\n",
    "test_id = test[\"Id\"]\n",
    "train = train.drop(columns=[\"SalePrice\"])\n",
    "full = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "\n",
    "num_cols = full.select_dtypes(include=[np.number]).columns\n",
    "obj_cols = full.select_dtypes(include=[\"object\"]).columns\n",
    "full[num_cols] = full[num_cols].fillna(0)\n",
    "full[obj_cols] = full[obj_cols].fillna(\"None\")\n",
    "\n",
    "skew_cols = [\"LotArea\",\"GrLivArea\",\"1stFlrSF\",\"2ndFlrSF\",\"TotalBsmtSF\",\"LowQualFinSF\"]\n",
    "for c in skew_cols:\n",
    "    if c in full.columns:\n",
    "        full[c] = np.log1p(full[c])\n",
    "\n",
    "full[\"TotalSF\"] = full[\"TotalBsmtSF\"] + full[\"1stFlrSF\"] + full[\"2ndFlrSF\"]\n",
    "full[\"Qual_x_GrLiv\"] = full[\"OverallQual\"] * full[\"GrLivArea\"]\n",
    "full[\"HouseAge\"] = (full[\"YrSold\"] - full[\"YearBuilt\"]).clip(lower=0)\n",
    "full[\"RemodAge\"] = (full[\"YrSold\"] - full[\"YearRemodAdd\"]).clip(lower=0)\n",
    "full[\"HasBsmt\"] = (full[\"TotalBsmtSF\"] > 0).astype(int)\n",
    "\n",
    "drop_cols = [\"Street\",\"Utilities\",\"Condition2\",\"RoofMatl\",\"PoolArea\",\"PoolQC\",\"MiscVal\",\"MiscFeature\"]\n",
    "for c in drop_cols:\n",
    "    if c in full.columns:\n",
    "        full = full.drop(columns=[c])\n",
    "\n",
    "full = pd.get_dummies(full, drop_first=True)\n",
    "\n",
    "n_train = len(y)\n",
    "X = full.iloc[:n_train, :].copy()\n",
    "X_test = full.iloc[n_train:, :].copy()\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rmse_scorer = make_scorer(lambda yt, yp: np.sqrt(mean_squared_error(yt, yp)), greater_is_better=False)\n",
    "\n",
    "# ===== MODEL GỐC (đang 0.11854) =====\n",
    "base = XGBRegressor(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.02,\n",
    "    max_depth=3,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.6,\n",
    "    min_child_weight=2,\n",
    "    reg_lambda=1.2,\n",
    "    reg_alpha=0.001,\n",
    "    gamma=0.0,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\"\n",
    ")\n",
    "\n",
    "# ===== MODEL TUNED NHẸ =====\n",
    "tuned = XGBRegressor(\n",
    "    n_estimators=2400,          # +200~400 cây\n",
    "    learning_rate=0.018,        # chậm hơn xíu\n",
    "    max_depth=3,                # giữ nguyên\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.55,\n",
    "    colsample_bylevel=0.7,      # thêm cái này\n",
    "    min_child_weight=3,         # tăng nhẹ để đỡ overfit\n",
    "    reg_lambda=1.4,\n",
    "    reg_alpha=0.01,\n",
    "    gamma=0.0,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\"\n",
    ")\n",
    "\n",
    "print(\"=== BASE ===\")\n",
    "scores_base = -cross_val_score(base, X, y, scoring=rmse_scorer, cv=kf)\n",
    "print(f\"BASE XGB: {scores_base.mean():.5f} ± {scores_base.std():.5f}\")\n",
    "\n",
    "print(\"=== TUNED ===\")\n",
    "scores_tuned = -cross_val_score(tuned, X, y, scoring=rmse_scorer, cv=kf)\n",
    "print(f\"TUNED XGB: {scores_tuned.mean():.5f} ± {scores_tuned.std():.5f}\")\n",
    "\n",
    "# nếu tuned tốt hơn -> train full + predict\n",
    "best = tuned if scores_tuned.mean() < scores_base.mean() else base\n",
    "best.fit(X, y)\n",
    "pred = np.expm1(best.predict(X_test))\n",
    "\n",
    "sub = pd.DataFrame({\"Id\": test_id, \"SalePrice\": pred})\n",
    "sub.to_csv(\"submission_best_xgb.csv\", index=False)\n",
    "print(\"✅ saved submission_best_xgb.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1482d1d0-ce15-4582-889d-6dda613f742a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV blend (log): 0.11936\n",
      "✅ saved submission_blend_xgb_stable.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# ===== 1. LOAD =====\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test  = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# drop outlier kinh điển\n",
    "train = train.drop(train[(train[\"GrLivArea\"] > 4000) & (train[\"SalePrice\"] < 300000)].index)\n",
    "\n",
    "y = np.log1p(train[\"SalePrice\"])\n",
    "test_id = test[\"Id\"]\n",
    "\n",
    "train = train.drop(columns=[\"SalePrice\"])\n",
    "full = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "\n",
    "# ===== 2. CLEAN =====\n",
    "num_cols = full.select_dtypes(include=[np.number]).columns\n",
    "obj_cols = full.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "full[num_cols] = full[num_cols].fillna(0)\n",
    "full[obj_cols] = full[obj_cols].fillna(\"None\")\n",
    "\n",
    "# ===== 3. FEATURE CƠ BẢN =====\n",
    "skew_cols = [\"LotArea\",\"GrLivArea\",\"1stFlrSF\",\"2ndFlrSF\",\"TotalBsmtSF\",\"LowQualFinSF\"]\n",
    "for c in skew_cols:\n",
    "    if c in full.columns:\n",
    "        full[c] = np.log1p(full[c])\n",
    "\n",
    "full[\"TotalSF\"] = full[\"TotalBsmtSF\"] + full[\"1stFlrSF\"] + full[\"2ndFlrSF\"]\n",
    "full[\"Qual_x_GrLiv\"] = full[\"OverallQual\"] * full[\"GrLivArea\"]\n",
    "full[\"HouseAge\"] = (full[\"YrSold\"] - full[\"YearBuilt\"]).clip(lower=0)\n",
    "full[\"RemodAge\"] = (full[\"YrSold\"] - full[\"YearRemodAdd\"]).clip(lower=0)\n",
    "full[\"HasBsmt\"] = (full[\"TotalBsmtSF\"] > 0).astype(int)\n",
    "\n",
    "drop_cols = [\"Street\",\"Utilities\",\"Condition2\",\"RoofMatl\",\"PoolQC\",\"MiscVal\",\"MiscFeature\",\"Alley\",\"Fence\"]\n",
    "for c in drop_cols:\n",
    "    if c in full.columns:\n",
    "        full = full.drop(columns=[c])\n",
    "\n",
    "# one-hot\n",
    "full = pd.get_dummies(full, drop_first=True)\n",
    "\n",
    "# ===== 4. SPLIT LẠI =====\n",
    "n_train = len(y)\n",
    "X = full.iloc[:n_train, :].copy()\n",
    "X_test = full.iloc[n_train:, :].copy()\n",
    "\n",
    "# ===== 5. CV \"AN TOÀN HƠN\" =====\n",
    "# sort theo YearSold + Neighborhood để giảm leakage thời gian/khu vực\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2025)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "oof = np.zeros(len(X))\n",
    "preds = np.zeros(len(X_test))\n",
    "\n",
    "# 3 cấu hình gần nhau → average để ổn định\n",
    "configs = [\n",
    "    dict(n_estimators=1800, learning_rate=0.02, max_depth=3,\n",
    "         subsample=0.9, colsample_bytree=0.55,\n",
    "         min_child_weight=4, reg_lambda=1.0, reg_alpha=0.01),\n",
    "    dict(n_estimators=2000, learning_rate=0.018, max_depth=3,\n",
    "         subsample=0.85, colsample_bytree=0.6,\n",
    "         min_child_weight=5, reg_lambda=1.2, reg_alpha=0.02),\n",
    "    dict(n_estimators=1600, learning_rate=0.022, max_depth=3,\n",
    "         subsample=0.9, colsample_bytree=0.5,\n",
    "         min_child_weight=6, reg_lambda=1.3, reg_alpha=0.03),\n",
    "]\n",
    "\n",
    "oof_preds_all = []\n",
    "test_preds_all = []\n",
    "\n",
    "for cfg in configs:\n",
    "    oof_cfg = np.zeros(len(X))\n",
    "    test_cfg = np.zeros(len(X_test))\n",
    "    for fold, (tr_idx, va_idx) in enumerate(folds.split(X, y)):\n",
    "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "        model = XGBRegressor(\n",
    "            **cfg,\n",
    "            gamma=0.0,\n",
    "            random_state=42 + fold,\n",
    "            tree_method=\"hist\"\n",
    "        )\n",
    "        model.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], verbose=False)\n",
    "        va_pred = model.predict(X_va)\n",
    "        oof_cfg[va_idx] = va_pred\n",
    "        test_cfg += model.predict(X_test) / folds.n_splits\n",
    "\n",
    "    oof_preds_all.append(oof_cfg)\n",
    "    test_preds_all.append(test_cfg)\n",
    "\n",
    "# average 3 cấu hình\n",
    "oof_blend = np.mean(oof_preds_all, axis=0)\n",
    "test_blend = np.mean(test_preds_all, axis=0)\n",
    "\n",
    "cv_score = rmse(y, oof_blend)\n",
    "print(f\"CV blend (log): {cv_score:.5f}\")\n",
    "\n",
    "# ===== 6. SUBMISSION =====\n",
    "sub = pd.DataFrame({\n",
    "    \"Id\": test_id,\n",
    "    \"SalePrice\": np.expm1(test_blend)\n",
    "})\n",
    "sub.to_csv(\"submission_blend_xgb_stable.csv\", index=False)\n",
    "print(\"✅ saved submission_blend_xgb_stable.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49d253f5-9876-46b2-b138-5a008572fff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB CV: 0.12083615499952262\n",
      "Lasso CV (pseudo): 0.10644273727642789\n",
      "ENet CV (pseudo): 0.09456316665158937\n",
      "BLEND CV: 0.10968028807417862\n",
      "✅ saved submission_xgb_lasso_enet.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nhan/active/myenv/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.223e+00, tolerance: 2.328e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# ========== 1. LOAD ==========\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test  = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# drop outlier kinh điển\n",
    "train = train.drop(train[(train[\"GrLivArea\"] > 4000) & (train[\"SalePrice\"] < 300000)].index)\n",
    "\n",
    "y = np.log1p(train[\"SalePrice\"])\n",
    "test_id = test[\"Id\"]\n",
    "\n",
    "train = train.drop(columns=[\"SalePrice\"])\n",
    "full = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "\n",
    "# ========== 2. BASIC CLEAN ==========\n",
    "num_cols = full.select_dtypes(include=[np.number]).columns\n",
    "obj_cols = full.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "full[num_cols] = full[num_cols].fillna(0)\n",
    "full[obj_cols] = full[obj_cols].fillna(\"None\")\n",
    "\n",
    "# ========== 3. FEATURE ENGINEERING NHANH ==========\n",
    "skew_cols = [\"LotArea\",\"GrLivArea\",\"1stFlrSF\",\"2ndFlrSF\",\"TotalBsmtSF\",\"LowQualFinSF\"]\n",
    "for c in skew_cols:\n",
    "    if c in full.columns:\n",
    "        full[c] = np.log1p(full[c])\n",
    "\n",
    "full[\"TotalSF\"] = full[\"TotalBsmtSF\"] + full[\"1stFlrSF\"] + full[\"2ndFlrSF\"]\n",
    "full[\"Qual_x_GrLiv\"] = full[\"OverallQual\"] * full[\"GrLivArea\"]\n",
    "full[\"HouseAge\"] = (full[\"YrSold\"] - full[\"YearBuilt\"]).clip(lower=0)\n",
    "full[\"RemodAge\"] = (full[\"YrSold\"] - full[\"YearRemodAdd\"]).clip(lower=0)\n",
    "full[\"HasBsmt\"] = (full[\"TotalBsmtSF\"] > 0).astype(int)\n",
    "\n",
    "drop_cols = [\"Street\",\"Utilities\",\"Condition2\",\"RoofMatl\",\"PoolQC\",\"MiscVal\",\"MiscFeature\",\"Alley\",\"Fence\"]\n",
    "for c in drop_cols:\n",
    "    if c in full.columns:\n",
    "        full = full.drop(columns=[c])\n",
    "\n",
    "# one-hot\n",
    "full = pd.get_dummies(full, drop_first=True)\n",
    "\n",
    "# ========== 4. SPLIT LẠI ==========\n",
    "n_train = len(y)\n",
    "X = full.iloc[:n_train, :].copy()\n",
    "X_test = full.iloc[n_train:, :].copy()\n",
    "\n",
    "# ========== 5. CV SETUP ==========\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=2025)\n",
    "\n",
    "# ========== 6. MODEL 1: XGB STABLE ==========\n",
    "xgb_params = dict(\n",
    "    n_estimators=1800,\n",
    "    learning_rate=0.02,\n",
    "    max_depth=3,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.55,\n",
    "    min_child_weight=4,\n",
    "    reg_lambda=1.0,\n",
    "    reg_alpha=0.01,\n",
    "    gamma=0.0,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\"\n",
    ")\n",
    "\n",
    "oof_xgb = np.zeros(len(X))\n",
    "pred_xgb = np.zeros(len(X_test))\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(kf.split(X, y)):\n",
    "    X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "    y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "    m = XGBRegressor(**xgb_params)\n",
    "    m.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], verbose=False)\n",
    "\n",
    "    oof_xgb[va_idx] = m.predict(X_va)\n",
    "    pred_xgb += m.predict(X_test) / kf.n_splits\n",
    "\n",
    "print(\"XGB CV:\", rmse(y, oof_xgb))\n",
    "\n",
    "# ========== 7. MODEL 2: LASSO ==========\n",
    "# Lasso cần scale nhẹ, nhưng ở đây full đã one-hot + khá ổn nên dùng trực tiếp\n",
    "lasso = LassoCV(\n",
    "    alphas=[1e-3, 3e-3, 1e-2, 3e-2, 1e-1],\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    max_iter=20000\n",
    ")\n",
    "lasso.fit(X, y)\n",
    "oof_lasso = lasso.predict(X)\n",
    "pred_lasso = lasso.predict(X_test)\n",
    "print(\"Lasso CV (pseudo):\", rmse(y, oof_lasso))\n",
    "\n",
    "# ========== 8. MODEL 3: ELASTICNET ==========\n",
    "enet = ElasticNetCV(\n",
    "    l1_ratio=[.1, .3, .5, .7, .9, .95],\n",
    "    alphas=[1e-3, 3e-3, 1e-2, 3e-2, 1e-1],\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    max_iter=20000\n",
    ")\n",
    "enet.fit(X, y)\n",
    "oof_enet = enet.predict(X)\n",
    "pred_enet = enet.predict(X_test)\n",
    "print(\"ENet CV (pseudo):\", rmse(y, oof_enet))\n",
    "\n",
    "# ========== 9. BLEND ==========\n",
    "# trọng số có thể thử: 0.6 / 0.25 / 0.15 hoặc 0.65 / 0.2 / 0.15\n",
    "oof_blend = 0.65 * oof_xgb + 0.2 * oof_lasso + 0.15 * oof_enet\n",
    "pred_blend = 0.65 * pred_xgb + 0.2 * pred_lasso + 0.15 * pred_enet\n",
    "\n",
    "cv_blend = rmse(y, oof_blend)\n",
    "print(\"BLEND CV:\", cv_blend)\n",
    "\n",
    "# ========== 10. SUBMISSION ==========\n",
    "sub = pd.DataFrame({\n",
    "    \"Id\": test_id,\n",
    "    \"SalePrice\": np.expm1(pred_blend)\n",
    "})\n",
    "sub.to_csv(\"submission_xgb_lasso_enet.csv\", index=False)\n",
    "print(\"✅ saved submission_xgb_lasso_enet.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dd9975-839a-4720-8c75-644d4aed5043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# ===== 1. load & prep nhanh như lúc nãy =====\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test  = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# drop outlier kinh điển\n",
    "train = train.drop(train[(train[\"GrLivArea\"] > 4000) & (train[\"SalePrice\"] < 300000)].index)\n",
    "\n",
    "y = np.log1p(train[\"SalePrice\"]).reset_index(drop=True)\n",
    "test_id = test[\"Id\"]\n",
    "\n",
    "train = train.drop(columns=[\"SalePrice\"])\n",
    "full = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "\n",
    "num_cols = full.select_dtypes(include=[np.number]).columns\n",
    "obj_cols = full.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "full[num_cols] = full[num_cols].fillna(0)\n",
    "full[obj_cols] = full[obj_cols].fillna(\"None\")\n",
    "\n",
    "# fe đơn giản\n",
    "full[\"TotalSF\"] = full[\"TotalBsmtSF\"] + full[\"1stFlrSF\"] + full[\"2ndFlrSF\"]\n",
    "full[\"HouseAge\"] = (full[\"YrSold\"] - full[\"YearBuilt\"]).clip(lower=0)\n",
    "full[\"RemodAge\"] = (full[\"YrSold\"] - full[\"YearRemodAdd\"]).clip(lower=0)\n",
    "full[\"Qual_x_GrLiv\"] = full[\"OverallQual\"] * full[\"GrLivArea\"]\n",
    "\n",
    "drop_cols = [\"Street\",\"Utilities\",\"Condition2\",\"RoofMatl\",\"PoolQC\",\"MiscVal\",\n",
    "             \"MiscFeature\",\"Alley\",\"Fence\"]\n",
    "for c in drop_cols:\n",
    "    if c in full.columns:\n",
    "        full = full.drop(columns=[c])\n",
    "\n",
    "full = pd.get_dummies(full, drop_first=True)\n",
    "\n",
    "n_train = len(y)\n",
    "X = full.iloc[:n_train, :].reset_index(drop=True)\n",
    "X_test = full.iloc[n_train:, :].reset_index(drop=True)\n",
    "\n",
    "# ===== 2. KFold =====\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=2025)\n",
    "\n",
    "oof_xgb = np.zeros(n_train)\n",
    "oof_lasso = np.zeros(n_train)\n",
    "oof_enet = np.zeros(n_train)\n",
    "\n",
    "pred_xgb = np.zeros(len(X_test))\n",
    "pred_lasso = np.zeros(len(X_test))\n",
    "pred_enet = np.zeros(len(X_test))\n",
    "\n",
    "# ===== 3. loop fold =====\n",
    "for fold, (tr_idx, va_idx) in enumerate(kf.split(X, y), 1):\n",
    "    X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "    y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "    # 3.1 XGB (shallow ổn định)\n",
    "    xgb = XGBRegressor(\n",
    "        n_estimators=1600,\n",
    "        learning_rate=0.025,\n",
    "        max_depth=3,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.55,\n",
    "        min_child_weight=4,\n",
    "        reg_lambda=1.0,\n",
    "        reg_alpha=0.01,\n",
    "        random_state=42,\n",
    "        tree_method=\"hist\"\n",
    "    )\n",
    "    xgb.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], verbose=False)\n",
    "    oof_xgb[va_idx] = xgb.predict(X_va)\n",
    "    pred_xgb += xgb.predict(X_test) / kf.n_splits\n",
    "\n",
    "    # 3.2 Lasso (fit trong fold, không leak)\n",
    "    lasso = Lasso(alpha=0.0007, max_iter=20000, random_state=42)\n",
    "    lasso.fit(X_tr, y_tr)\n",
    "    oof_lasso[va_idx] = lasso.predict(X_va)\n",
    "    pred_lasso += lasso.predict(X_test) / kf.n_splits\n",
    "\n",
    "    # 3.3 ElasticNet\n",
    "    enet = ElasticNet(alpha=0.0008, l1_ratio=0.7, max_iter=20000, random_state=42)\n",
    "    enet.fit(X_tr, y_tr)\n",
    "    oof_enet[va_idx] = enet.predict(X_va)\n",
    "    pred_enet += enet.predict(X_test) / kf.n_splits\n",
    "\n",
    "# ===== 4. đánh giá từng model thật =====\n",
    "print(\"XGB OOF  :\", rmse(y, oof_xgb))\n",
    "print(\"Lasso OOF:\", rmse(y, oof_lasso))\n",
    "print(\"ENet OOF :\", rmse(y, oof_enet))\n",
    "\n",
    "# ===== 5. meta-learner (stacking level 2) =====\n",
    "# train 1 linear nhỏ để học trọng số\n",
    "stack_X = np.vstack([oof_xgb, oof_lasso, oof_enet]).T\n",
    "stack_test = np.vstack([pred_xgb, pred_lasso, pred_enet]).T\n",
    "\n",
    "meta = Lasso(alpha=0.0001, max_iter=10000)\n",
    "meta.fit(stack_X, y)\n",
    "oof_blend = meta.predict(stack_X)\n",
    "pred_blend = meta.predict(stack_test)\n",
    "\n",
    "print(\"STACK OOF:\", rmse(y, oof_blend))\n",
    "print(\"meta coefs:\", meta.coef_, \"intercept:\", meta.intercept_)\n",
    "\n",
    "# ===== 6. submission =====\n",
    "sub = pd.DataFrame({\n",
    "    \"Id\": test_id,\n",
    "    \"SalePrice\": np.expm1(pred_blend)\n",
    "})\n",
    "sub.to_csv(\"submission_stack_xgb_linear.csv\", index=False)\n",
    "print(\"✅ saved submission_stack_xgb_linear.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
