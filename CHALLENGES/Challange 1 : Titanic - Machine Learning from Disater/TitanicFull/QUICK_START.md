# ğŸš€ Quick Start Guide - Titanic ML Template

## Má»¥c Ä‘Ã­ch
Táº¡o má»™t **experiment má»›i** Ä‘á»ƒ test thá»­ preprocessing hoáº·c model má»›i.

## âš¡ BÆ°á»›c nhanh (5 phÃºt)

### 1ï¸âƒ£ Táº¡o thÆ° má»¥c má»›i
```bash
# Táº¡o thÆ° má»¥c ngÃ y hÃ´m nay (vÃ­ dá»¥: 24/10/2025)
mkdir -p process/test_24102025/{eda,model,runs}
```

### 2ï¸âƒ£ Copy notebook tá»« experiment trÆ°á»›c
```bash
# Copy tá»« experiment tá»‘t nháº¥t trÆ°á»›c Ä‘Ã³
cp process/test_23102025/model/train.ipynb process/test_24102025/model/
cp process/test_23102025/eda/eda01.ipynb process/test_24102025/eda/  # TÃ¹y chá»n
```

### 3ï¸âƒ£ Táº¡o file orchestrator
```bash
# Táº¡o file main_24102025.ipynb trong thÆ° má»¥c runs
```

### 4ï¸âƒ£ Chá»‰nh sá»­a config trong train.ipynb

Má»Ÿ `process/test_24102025/model/train.ipynb` vÃ  tÃ¬m pháº§n config (Cell 2):

```python
params_cfg = {
    "action"   : "train_feat03",  
    "feat_path": "../../exps/featbase_24102025/data.npz",  # â† Äá»•i tÃªn
    "seed"     : 42,
    "exp_dir"  : os.path.abspath('../../exps'),
    'exp_name' : 'trainbase_24102025',  # â† Äá»•i tÃªn
    "data_dir" : os.path.abspath("../../../data"),
    "verbose"  : True,
}
```

### 5ï¸âƒ£ Cháº¡y experiment
```bash
cd process/test_24102025/runs
jupyter notebook main_24102025.ipynb
```

---

## ğŸ“ Template main_<DATE>.ipynb

Copy vÃ o file `process/test_24102025/runs/main_24102025.ipynb`:

```python
# Cell 1: Import
from IPython import display

# Cell 2: Clear output (optional)
display.clear_output()

# Cell 3: Run train notebook
%run ../model/train.ipynb

# Cell 4: Export HTML (optional)
!jupyter nbconvert ../model/train.ipynb --to html

# Cell 5: Load data vÃ  train model
# (Copy code tá»« test_23102025/runs/main_23102025.ipynb)
```

---

## ğŸ¯ CÃ¡c thay Ä‘á»•i thÆ°á»ng gáº·p

### Thay Ä‘á»•i preprocessing
Sá»­a function `preprocessing_feature_01()` trong `train.ipynb`:

```python
def preprocessing_feature_01(df_data, is_train=True, is_debug=True, **kwargs):
    df_output = pd.DataFrame()
    
    # ThÃªm features má»›i á»Ÿ Ä‘Ã¢y
    # VÃ­ dá»¥: df_output['new_feature'] = ...
    
    return df_output, None
```

### Thay Ä‘á»•i hyperparameters
TÃ¬m param_grid trong cell training vÃ  chá»‰nh sá»­a:

```python
param_grid = {
    'logreg__C': [0.1, 1, 10],  # ThÃªm/bá»›t values
    'logreg__penalty': ['l2'],   # Chá»‰ test l2
}
```

### Thay Ä‘á»•i model
ThÃªm/sá»­a model trong `train.ipynb`:

```python
from sklearn.ensemble import GradientBoostingClassifier

pipeline_gb = Pipeline([
    ('scaler', StandardScaler()),
    ('gb', GradientBoostingClassifier(random_state=42))
])
```

---

## ğŸ“Š Xem káº¿t quáº£

### 1. Submission files
Kiá»ƒm tra trong: `process/exps/trainbase_24102025/`
- `submission_xgboost.csv`
- `submission_voting.csv`
- etc.

### 2. Model files
- `xgboost_model.pkl`: Model tá»‘t nháº¥t
- `data.npz`: Dá»¯ liá»‡u Ä‘Ã£ preprocess

### 3. So sÃ¡nh vá»›i experiment trÆ°á»›c
```bash
# Xem record
cat process/exps/record.xlsx

# Hoáº·c xem README cá»§a tá»«ng experiment
cat process/test_24102025/README.md
```

---

## ğŸ’¡ Tips

1. **TÃªn experiment:**
   - Format: `trainbase_<DDMMYYYY>`
   - VÃ­ dá»¥: `trainbase_24102025`

2. **Backup:**
   - Commit code vÃ o git trÆ°á»›c khi cháº¡y
   - Giá»¯ láº¡i file notebook cá»§a experiment tá»‘t nháº¥t

3. **Debug:**
   - Set `"verbose": True` trong config Ä‘á»ƒ in thÃ´ng tin
   - Set `is_debug=True` trong `preprocessing_feature_01()`

4. **Nhanh hÆ¡n:**
   - Giáº£m GridSearchCV param_grid khi test nhanh
   - Chá»‰ train 1 model khi test preprocessing

---

## ğŸ› Troubleshooting

### Lá»—i: File not found
```python
# Kiá»ƒm tra Ä‘Æ°á»ng dáº«n relative
print(os.getcwd())  # Current working directory
print(os.path.abspath('../../../data'))  # Check path
```

### Lá»—i: Model chÆ°a train
```python
# Kiá»ƒm tra xem model Ä‘Ã£ fit chÆ°a
print(hasattr(model, 'feature_importances_'))
```

### Lá»—i: Memory issue
- Giáº£m param_grid size
- TÄƒng `n_jobs` trong GridSearchCV
- XÃ³a output cells cÅ© trong notebook

---

## ğŸ“š Next Steps

1. **Improve feature engineering** â†’ Edit `preprocessing_feature_01()`
2. **Try different models** â†’ Add new model cells
3. **Ensemble methods** â†’ Implement voting/stacking/blending
4. **Submit to Kaggle** â†’ Upload `submission_*.csv`
5. **Document results** â†’ Update README.md
