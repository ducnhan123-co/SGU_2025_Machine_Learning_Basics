# ğŸ“ Cáº¥u trÃºc dá»± Ã¡n chi tiáº¿t

## ğŸ¯ NguyÃªn táº¯c thiáº¿t káº¿

Dá»± Ã¡n Ä‘Æ°á»£c thiáº¿t káº¿ theo nguyÃªn táº¯c systems, in the sáº£n khoa há»c:

1. **TÃ¡ch biá»‡t dá»¯ liá»‡u gá»‘c** (`data/`) vÃ  dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½ (`exps/`)
2. **Versioning experiments** theo ngÃ y thÃ¡ng
3. **TÃ¡i sá»­ dá»¥ng code** giá»¯a cÃ¡c experiments
4. **Ghi chÃ©p káº¿t quáº£** Ä‘á»ƒ so sÃ¡nh

---

## ğŸ“ Cáº¥u trÃºc phÃ¢n cáº¥p

```
TitanicFull/
â”‚
â”œâ”€â”€ ğŸ“‚ data/                          â”€â”€â”€â”€â”€â”
â”‚   â”œâ”€â”€ train.csv                         â”‚ Dá»® LIá»†U Gá»C
â”‚   â”œâ”€â”€ test.csv                          â”‚ (chá»‰ Ä‘á»c)
â”‚   â””â”€â”€ gender_submission.csv             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚
â”œâ”€â”€ ğŸ“‚ process/
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ exps/                      â”€â”€â”€â”
â”‚   â”‚   â”œâ”€â”€ record.xlsx                  â”‚ Káº¾T QUáº¢
â”‚   â”‚   â””â”€â”€ trainbase_23102025/          â”‚ EXPERIMENTS
â”‚   â”‚       â”œâ”€â”€ data.npz                 â”‚
â”‚   â”‚       â”œâ”€â”€ *_model.pkl              â”‚
â”‚   â”‚       â”œâ”€â”€ submission_*.csv         â”‚
â”‚   â”‚       â””â”€â”€ *_package.pkl            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ test_23102025/             â”€â”€â”€â”
â”‚       â”œâ”€â”€ README.md                     â”‚
â”‚       â”œâ”€â”€ ğŸ“‚ eda/                       â”‚ NOTEBOOK
â”‚       â”‚   â””â”€â”€ eda01.ipynb               â”‚ WORKFLOW
â”‚       â”œâ”€â”€ ğŸ“‚ model/                     â”‚
â”‚       â”‚   â”œâ”€â”€ train.ipynb  â­ CORE      â”‚
â”‚       â”‚   â””â”€â”€ train.html                â”‚
â”‚       â””â”€â”€ ğŸ“‚ runs/                      â”‚
â”‚           â”œâ”€â”€ main_23102025.ipynb      â”‚
â”‚           â””â”€â”€ test_predictions.npy      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚
â””â”€â”€ ğŸ“„ README.md
```

---

## ğŸ”„ Luá»“ng dá»¯ liá»‡u (Data Flow)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     WORKFLOW EXPERIMENT                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. DATA INGESTION
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  data/*.csv â”‚ â”€â”€â”€â”€Readâ”€â”€> â”‚ train.ipynb â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

2. PREPROCESSING
   â”‚ train.ipynb â”‚ â”€â”€Preprocessâ”€> â”‚ df_output â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

3. SAVE PROCESSED DATA
   â”‚ df_output â”‚ â”€â”€np.savezâ”€â”€> â”‚ exps/.../data.npz â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

4. MODEL TRAINING
   â”‚ exps/.../data.npz â”‚ â”€â”€Loadâ”€â”€> â”‚ GridSearchCV â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    v
                              â”‚ best_model thumb â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

5. SAVE MODEL
   â”‚ best_model â”‚ â”€â”€joblib.dumpâ”€â”€> â”‚ exps/.../*_model.pkl â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

6. PREDICTION
   â”‚ *_model.pkl â”‚ â”€â”€Loadâ”€â”€> â”‚ model.predict(X_test) â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

7. SUBMISSION
   â”‚ predictions â”‚ â”€â”€to_csvâ”€â”€> â”‚ exps/.../submission_*.csv â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ TrÃ¡ch nhiá»‡m tá»«ng file

### Data Layer

| File | Nhiá»‡m vá»¥ | Ghi chÃº |
|------|----------|---------|
| `data/train.csv` | Dá»¯ liá»‡u training vá»›i nhÃ£n | 891 samples, khÃ´ng thay Ä‘á»•i |
| `data/test.csv` | Dá»¯ liá»‡u test khÃ´ng nhÃ£n | 418 samples, khÃ´ng thay Ä‘á»•i |
| `data/gender_submission.csv` | Máº«u format submission | Template cho Kaggle |

### Experiment Layer

| File | Nhiá»‡m vá»¥ | Cáº¥u trÃºc |
|------|----------|----------|
| `exps/trainbase_YYYYMMDD/data.npz` | Dá»¯ liá»‡u Ä‘Ã£ preprocess | {train_data, test_data, columns} |
| `exps/trainbase_YYYYMMDD/*_model.pkl` | Model Ä‘Ã£ train | Pipeline vá»›i preprocessing + model |
| `exps/trainbase_YYYYMMDD/submission_*.csv` | File submission | {PassengerId, Survived} |
| `exps/trainbase_YYYYMMDD/*_package.pkl` | Package model + metadata | {model, features, scaler, date} |
| `exps/record.xlsx` | Tá»•ng há»£p káº¿t quáº£ | Excel so sÃ¡nh experiments |

### Code Layer

| File | Nhiá»‡m vá»¥ | Chá»©c nÄƒng chÃ­nh |
|------|----------|-----------------|
| `test_*/README.md` | Documentation | MÃ´ táº£ thay Ä‘á»•i, káº¿t quáº£ |
| `test_*/eda/eda01.ipynb` | Exploratory Data Analysis | PhÃ¢n tÃ­ch, visualization |
| `test_*/model/train.ipynb` | **Core logic** â­ | Preprocessing + Training |
| `test_*/model/train.html` | Exported notebook | View offline |
| `test_*/runs/main_YYYYMMDD.ipynb` | Orchestrator | Run toÃ n bá»™ workflow |
| `test_*/runs/test_predictions.npy` | Predictions cache | Numpy array |

---

## ğŸ¬ Workflow Step by Step

### Phase 1: Setup
```python
# 1. Táº¡o thÆ° má»¥c
mkdir process/test_YYYYMMDD/{eda,model,runs}

# 2. Copy code tá»« experiment trÆ°á»›c
cp process/test_OLD/model/train.ipynb process/test_NEW/model/

# 3. Cáº­p nháº­t config trong train.ipynb
exp_name = 'trainbase_YYYYMMDD'
```

### Phase 2: Data Processing
```python
# Trong train.ipynb
df_train = pd.read_csv(f'{data_dir}/train.csv')
df_test = pd.read_csv(f'{data_dir}/test.csv')

# Preprocessing
df_output_train, _ = preprocessing_feature_01(df_train, is_train=True)
df_output_test, _ = preprocessing_feature_01(df_test, is_train=False)

# Save
np.savez(f'{save_dir}/data.npz', 
         train_data=df_output_train.values,
         test_data=df_output_test.values,
         train_columns=df_output_train.columns.values)
```

### Phase 3: Model Training
```python
# Load processed data
data = np.load('exps/trainbase_YYYYMMDD/data.npz', allow_pickle=True)
df_train = pd.DataFrame(data['train_data'], columns=data['train_columns'])

# Split features and target
X_train = df_train.drop(columns=['Output'])
y_train = df_train['Output']

# GridSearchCV
grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

# Save best model
joblib.dump(grid_search.best_estimator_, 'exps/.../model.pkl')
```

### Phase 4: Prediction & Submission
```python
# Load model
model = joblib.load('exps/.../model.pkl')

# Predict
predictions = model.predict(X_test)

# Create submission
submission = pd.DataFrame({
    'PassengerId': test_data['PassengerId'],
    'Survived': predictions
})

submission.to_csv('exps/.../submission.csv', index=False)
```

---

## ğŸ”— Dependency Map

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ main_*.ipynb â”‚ â”€â”€â”€runâ”€â”€â”€> â”‚ train.ipynb â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â”œâ”€â”€â”€readâ”€â”€> â”‚ data/*.csv â”‚
                                    â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â”œâ”€â”€â”€writeâ”€â”€> â”‚ exps/.../data.npz â”‚
                                    â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â”œâ”€â”€â”€writeâ”€â”€> â”‚ exps/.../model.pkl â”‚
                                    â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â””â”€â”€â”€writeâ”€â”€> â”‚ exps/.../submission.csv â”‚
                                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ runs/*.ipynb â”‚ â”€â”€â”€loadâ”€â”€> â”‚ exps/.../data.npz â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚ exps/.../model.pkl â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’¾ File Format Notes

### .npz (Numpy Compressed)
```python
# LÆ°u
np.savez('data.npz', 
         train_data=X_train.values,
         train_columns=X_train.columns.values)

# Äá»c
data = np.load('data.npz', allow_pickle=True)
df = pd.DataFrame(data['train_data'], columns=data['train_columns'])
```

### .pkl (Pickle)
```python
# LÆ°u
joblib.dump(model, 'model.pkl')
joblib.dump({'model': model, 'features': features}, 'package.pkl')

# Äá»c
model = joblib.load('model.pkl')
pkg = joblib.load('package.pkl')
model = pkg['model']
```

### .csv (Submission)
```csv
PassengerId,Survived
892,0
893,1
...
```

---

## ğŸ¯ Best Practices

### âœ… DO
- LÆ°u processed data Ä‘á»ƒ tÃ¡i sá»­ dá»¥ng
- Äáº·t tÃªn experiment theo ngÃ y
- Ghi README cho má»—i experiment
- Commit code vÃ o git
- Backup model tá»‘t nháº¥t

### âŒ DON'T
- Sá»­a dá»¯ liá»‡u trong `data/`
- Ghi Ä‘Ã¨ experiment cÅ©
- Bá» qua documentation
- Hardcode paths
- KhÃ´ng track changes

---

## ğŸ”§ Config Template

```python
params_cfg = {
    "action"   : "train_feat03",           # Action type
    "feat_path": "../../exps/.../data.npz", # Path to processed data
    "seed"     : 42,                        # Random seed
    "exp_dir"  : "process/exps",            # Experiments directory
    "exp_name" : "trainbase_YYYYMMDD",      # Experiment name
    "data_dir" : "data",                    # Raw data directory
    "verbose"  : True,                      # Print info
}

# Auto create save_dir
params_cfg.update(**{
    "save_dir": f'{params_cfg["exp_dir"]}/{params_cfg["exp_name"]}'
})
```

---

## ğŸ“Š Experiment Tracking

### Record File Structure (record.xlsx)

| Experiment | Date | Model | Features | Accuracy | Notes |
|------------|------|-------|----------|----------|-------|
| trainbase_23102025 | 23/10/2025 | XGBoost | feat03 | 0.8664 | Baseline |
| trainbase_24102025 | 24/10/2025 | XGBoost | feat04 | 0.8700 | +new_feature |

---

## ğŸ“ Lessons Learned

1. **Separate concerns**: Data, Processing, Models
2. **Version everything**: Experiments, Code, Results
3. **Automate**: Use notebooks orchestrator
4. **Document**: README for each experiment
5. **Compare**: Use record.xlsx to track progress
